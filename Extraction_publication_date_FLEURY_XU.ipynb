{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "Determining the publication date of official documents is crucial for monitoring systems that track updates from French city councils, regions, and other entities. The challenge lies in the fact that documents appearing on websites may not reflect their actual publication dates. Factors such as website restructuring, new regulations, or editorial practices can result in significant discrepancies between the upload date and the true publication date.\n",
        "\n",
        "This project aims to address this challenge by developing a system to extract or predict the publication date of documents. Using a gold standard dataset, we will create and evaluate an extraction and prediction system. The ultimate goal is to ensure accurate identification of publication dates, providing reliable data for use in watch systems."
      ],
      "metadata": {
        "id": "K-sLmxT1ymwv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will present here two approaches: one using regular expressions (regex) and one using a model."
      ],
      "metadata": {
        "id": "2LVKAubIhnYK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**First step: Create a gold standard**\n",
        "\n",
        "We created a gold standard by manually annotating the first 500 documents. These gold dates are in a Hugging Face dataset (\"maribr/publication_dates_fr\")."
      ],
      "metadata": {
        "id": "k2jfBt0r0Nom"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Date extraction with regex"
      ],
      "metadata": {
        "id": "Yjbq50CHh2GW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analysis of the problem**\n",
        "\n",
        "Making the gold standard was a good way to observe our data. Here are a few observations, crucial to find a way on how to implement the problem:\n",
        "\n",
        "- Where to find publication dates? Usually at the very beginning or the very end of the document.\n",
        "\n",
        "- Which words indicate publication dates? \"**publié le\", \"date de publication\", \"affiché le\", \"date de mise en ligne\", \"disponible depuis\", \"fait à [...], le\"** for example.\n",
        "\n",
        "- However, usually there is no such explicit terms in the documents, so a way to solve this problem could be to extract all the dates in the document and select the latest date. However, the latest date could correspond to a measure that is going to be set up in the future. Thus, we could use the context surrounding the dates and remove them if in the same sentence we have the words \"**annonce**\" (verb \"annoncer\") or \"**à compter du**\", which announces a future measure, so these dates must not be taken into account. We also remove the date if there is any future tense in the sentence.\n",
        "\n",
        "- One problem that can't be solved for the moment: when the pdf files that don't have an url available for the 'text version', we offer to use a pdf text reader (PyPDF2). However, there are rare cases in our dataset where the pdf is not readable, and since there is no url text version, we don't have any mean to extract and analyze the text. A further implementation could be to use OCR but the few techniques available that we tried are not successful and reliable.\n",
        "\n",
        "Conclusions:\n",
        "\n",
        "- With **regular expressions**, we will search for dates that are surrounded by words related to publication (\"publié le\", \"mise en ligne\") with the additionnal criteria of these dates being at the very beggining or very end of the document. (Indeed, it happened that there is a \"publié le\" but talking about another document, within the document -in the middle.)\n",
        "\n",
        "- Since this way of search doesn't apply to every document (because it's not frequent to have explicits words like \"publié le\"), we will process the rest of the documents with a **global search** of the dates (still at the beginning or the end of the document) with **removing** the ones included in a sentence in a **future tense** or containing words like \"**annonce**\" and \"**à compter du**\".\n",
        "\n",
        "- Finally we will compare these dates to the one written in the url (if so) and choose the most recent date.\n"
      ],
      "metadata": {
        "id": "ylc-87kzigag"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preparation of the data**"
      ],
      "metadata": {
        "id": "ALLTDPLj1YYg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. Load our gold dataset (made on Hugging Face)"
      ],
      "metadata": {
        "id": "nd8IR_97Atmr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "fL7SQbbDFDHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6xK5U-EkBdIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "gold_dataset = load_dataset(\"maribr/publication_dates_fr\")"
      ],
      "metadata": {
        "id": "DzQHkNCEBXJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gold_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXZQcXbr0OEH",
        "outputId": "398a9855-b291-422b-8108-64a08cb700da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['Text', 'Gold published date', 'url'],\n",
              "        num_rows: 500\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a DatasetDict. So to use it, we only take the dataset (train):"
      ],
      "metadata": {
        "id": "jpQ_bFY-DXJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import DatasetDict\n",
        "train_dataset = gold_dataset[\"train\"]\n",
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dc4Zm6Z7DFEw",
        "outputId": "5804f35e-da31-4ab9-ca58-4a2d312d84ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['Text', 'Gold published date', 'url'],\n",
              "    num_rows: 500\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And then we can use pandas to work on a dataframe:"
      ],
      "metadata": {
        "id": "dEtyKUClDl_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_gold = train_dataset.to_pandas()\n",
        "print(df_gold.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLdUKwQDDkSU",
        "outputId": "6aa6ac5d-7a62-4227-f10c-c55c1991ece6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                Text Gold published date  \\\n",
            "0  PROCES-VERBAL DE LA REUNION PUBLIQUE\\nDU CONSE...          16/01/2023   \n",
            "1  CONSEIL COMMUNAUTAIRE DU\\n25 JANVIER 2023\\nPRO...          25/01/2023   \n",
            "2  Date de mise en ligne de\\nl’acte : 02/ 02/2023...          02/02/2023   \n",
            "3  Envoyé en préfecture le 26/01/2023\\nReçu en pr...          26/01/2023   \n",
            "4       \\nFait à Bourg-en-Bresse, le 23 janvier 2023          23/01/2023   \n",
            "\n",
            "                                                 url  \n",
            "0  http://www.ville-saint-ay.fr/userfile/fichier-...  \n",
            "1  https://www.gatine-racan.fr/wp-content/uploads...  \n",
            "2  https://www.ville-mazeres.fr/IMG/pdf/2023_1_1.pdf  \n",
            "3  https://www.fier-et-usses.com/cms_viewFile.php...  \n",
            "4  https://www.grandbourg.fr/cms_viewFile.php?idt...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. Load the original dataset.csv file"
      ],
      "metadata": {
        "id": "J-p5KWiKE3ze"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create a dataframe of the dataset.csv file containing the doc_id, url, cache, text version, nature, published, entity, entity_type."
      ],
      "metadata": {
        "id": "6xoKQ-KHERh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"dataset.csv\", nrows=500) # we only take the first 500 rows since we did the gold dates for the first 500 rows\n",
        "df.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "Sx5v6QRTAObN",
        "outputId": "f015e6a1-fb62-467c-b959-5f6b8fc3f3c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              doc_id  \\\n",
              "0  6357/71845_1698228833-PV---Conseil-Municipal-1...   \n",
              "1            2515/213c7_proces-verbal-25-01-2023.pdf   \n",
              "\n",
              "                                                 url  \\\n",
              "0  http://www.ville-saint-ay.fr/userfile/fichier-...   \n",
              "1  https://www.gatine-racan.fr/wp-content/uploads...   \n",
              "\n",
              "                                               cache  \\\n",
              "0  https://datapolitics-public.s3.gra.io.cloud.ov...   \n",
              "1  https://datapolitics-public.s3.gra.io.cloud.ov...   \n",
              "\n",
              "                                        text version nature   published  \\\n",
              "0  https://datapolitics-public.s3.gra.io.cloud.ov...  pv.cr  16/01/2023   \n",
              "1  https://datapolitics-public.s3.gra.io.cloud.ov...  pv.cr  25/01/2023   \n",
              "\n",
              "               entity       entity_type  \n",
              "0            Saint-Ay           Commune  \n",
              "1  CC de Gâtine-Racan  Intercommunalité  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-78cd2a8f-15d8-41c5-a1fe-f528f4365ba5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc_id</th>\n",
              "      <th>url</th>\n",
              "      <th>cache</th>\n",
              "      <th>text version</th>\n",
              "      <th>nature</th>\n",
              "      <th>published</th>\n",
              "      <th>entity</th>\n",
              "      <th>entity_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6357/71845_1698228833-PV---Conseil-Municipal-1...</td>\n",
              "      <td>http://www.ville-saint-ay.fr/userfile/fichier-...</td>\n",
              "      <td>https://datapolitics-public.s3.gra.io.cloud.ov...</td>\n",
              "      <td>https://datapolitics-public.s3.gra.io.cloud.ov...</td>\n",
              "      <td>pv.cr</td>\n",
              "      <td>16/01/2023</td>\n",
              "      <td>Saint-Ay</td>\n",
              "      <td>Commune</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2515/213c7_proces-verbal-25-01-2023.pdf</td>\n",
              "      <td>https://www.gatine-racan.fr/wp-content/uploads...</td>\n",
              "      <td>https://datapolitics-public.s3.gra.io.cloud.ov...</td>\n",
              "      <td>https://datapolitics-public.s3.gra.io.cloud.ov...</td>\n",
              "      <td>pv.cr</td>\n",
              "      <td>25/01/2023</td>\n",
              "      <td>CC de Gâtine-Racan</td>\n",
              "      <td>Intercommunalité</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-78cd2a8f-15d8-41c5-a1fe-f528f4365ba5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-78cd2a8f-15d8-41c5-a1fe-f528f4365ba5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-78cd2a8f-15d8-41c5-a1fe-f528f4365ba5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7d120f8f-c895-4c71-915c-4328097f5a3f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7d120f8f-c895-4c71-915c-4328097f5a3f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7d120f8f-c895-4c71-915c-4328097f5a3f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 500,\n  \"fields\": [\n    {\n      \"column\": \"doc_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"647/bb363_CR_CM_19_11_20.pdf\",\n          \"1930/d6f5f_PC-94078-2200041-1-MARS-2023.pdf\",\n          \"3897/612feb68823851ff36496e217abeb4bf0e68f8c6_Compte-rendu-som\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"https://www.ville-cachan.fr/images/CR_CM_19_11_20.pdf\",\n          \"https://www.villeneuve-saint-georges.fr/images/agenda/13112017/pdf/ACTES/URBANISME/2023/MARS/PC-94078-2200041-1-MARS-2023.pdf\",\n          \"https://www.gennesvaldeloire.fr/medias/2021/02/Compte-rendu-sommaire-du-08.02.2021.pdf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cache\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"https://datapolitics-public.s3.gra.io.cloud.ovh.net/LORIA/647/bb363_CR_CM_19_11_20.pdf\",\n          \"https://datapolitics-public.s3.gra.io.cloud.ovh.net/LORIA/1930/d6f5f_PC-94078-2200041-1-MARS-2023.pdf\",\n          \"https://datapolitics-public.s3.gra.io.cloud.ovh.net/LORIA/3897/612feb68823851ff36496e217abeb4bf0e68f8c6_Compte-rendu-som\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text version\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"https://datapolitics-public.s3.gra.io.cloud.ovh.net/LORIA/txt/647/bb363_CR_CM_19_11_20.pdf.txt\",\n          \"https://datapolitics-public.s3.gra.io.cloud.ovh.net/LORIA/txt/1930/d6f5f_PC-94078-2200041-1-MARS-2023.pdf.txt\",\n          \"https://datapolitics-public.s3.gra.io.cloud.ovh.net/LORIA/txt/3897/612feb68823851ff36496e217abeb4bf0e68f8c6_Compte-rendu-som.txt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nature\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"acte.delib\",\n          \"bdj\",\n          \"pv.cr\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"published\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 272,\n        \"samples\": [\n          \"21/02/2024\",\n          \"28/04/2023\",\n          \"01/02/2020\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"entity\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 292,\n        \"samples\": [\n          \"Pr\\u00e9fecture - Loz\\u00e8re\",\n          \"CC du Pays de Tarascon\",\n          \"CA \\u00c9tampois Sud Essonne\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"entity_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Commune\",\n          \"Intercommunalit\\u00e9\",\n          \"Autre partie prenante\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Explicit publication dates in the document"
      ],
      "metadata": {
        "id": "UN7c47WhLB1m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementation method:\n",
        "\n",
        "- We make a extract_text_from_pdf_url function to return the written text in the pdf, in the case where the url of text version (of our dataframe df) isn't working/available."
      ],
      "metadata": {
        "id": "WK7jXGsXcwzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "collapsed": true,
        "id": "5NwU90TTI9o7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Function to extract text from pdf (this function will be called inside the next function 'extract_publication_date')\n",
        "\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "def extract_text_from_pdf_url(url):\n",
        "    try:\n",
        "        # Load the content of the pdf from the url\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Verify if the request succeeded\n",
        "\n",
        "        # Load the pdf content in a binary flow\n",
        "        pdf_content = BytesIO(response.content)\n",
        "\n",
        "        # Read the pdf with PyPDF2\n",
        "        reader = PdfReader(pdf_content)\n",
        "        text = \"\"\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text()  # Extraire le texte de chaque page\n",
        "\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        return f\"Erreur lors de l'extraction du texte : {e}\""
      ],
      "metadata": {
        "id": "lDZbnxLaI1jN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import re\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Dictionnaire pour convertir les mois en chiffres\n",
        "mois_to_num = {\n",
        "    \"janvier\": \"01\", \"février\": \"02\", \"mars\": \"03\", \"avril\": \"04\", \"mai\": \"05\", \"juin\": \"06\",\n",
        "    \"juillet\": \"07\", \"août\": \"08\", \"septembre\": \"09\", \"octobre\": \"10\", \"novembre\": \"11\", \"décembre\": \"12\"\n",
        "}\n",
        "\n",
        "# Expressions régulières pour détecter les dates\n",
        "pattern_date = r'(\\d{1,2})\\s*(janvier|février|mars|avril|mai|juin|juillet|août|septembre|octobre|novembre|décembre)\\s*(\\d{4})|(\\d{1,2})\\s*\\/\\s*(\\d{1,2})\\s*\\/\\s*(\\d{4})'\n",
        "\n",
        "# Recherche des termes qui suggèrent une date de publication\n",
        "pattern_pub = r\"(publié|paru|date de publication|disponible depuis|affiché|affichage|mise en ligne|reçu|réception|télétransmission|adopté|rédigé|approuvé|révision|modification)\"\n",
        "\n",
        "def extract_publication_date(url):\n",
        "    # Requête HTTP pour récupérer le texte du document\n",
        "    response = requests.get(url)\n",
        "    if response.status_code != 200:  # Si le texte brut n'est pas disponible via l'URL\n",
        "        content = extract_text_from_pdf_url(df['url'])\n",
        "    else:  # Si le texte dans l'URL est disponible\n",
        "        content = response.text\n",
        "\n",
        "    # Découper le contenu en mots\n",
        "    words = content.split()\n",
        "\n",
        "    # Recherche des dates associées aux termes de publication\n",
        "    matches_pub = re.finditer(pattern_pub, content.lower())\n",
        "    dates_pub = []\n",
        "\n",
        "    for match in matches_pub:\n",
        "        # Trouver la position du match de la date de publication\n",
        "        start_index = match.end()\n",
        "\n",
        "        # Calculer la position du mot en cours\n",
        "        word_position = len(content[:start_index].split())\n",
        "\n",
        "        # Vérifier si la date est dans les 300 premiers mots ou les 150 derniers mots\n",
        "        if word_position <= 300 or word_position >= len(words) - 150:\n",
        "            # Extraire la date qui suit ces termes\n",
        "            sub_text = content[start_index:start_index + 75]  # Limite à 50 caractères après le terme de publication\n",
        "            date_matches = re.findall(pattern_date, sub_text)\n",
        "\n",
        "            for date_match in date_matches:\n",
        "                if date_match[0]:  # Format \"12 décembre 2023\"\n",
        "                    jour = date_match[0].zfill(2)\n",
        "                    mois = mois_to_num[date_match[1].lower()]\n",
        "                    annee = date_match[2]\n",
        "                    dates_pub.append(f\"{jour}/{mois}/{annee}\")\n",
        "                elif date_match[3]:  # Format \"12/12/2023\"\n",
        "                    jour = date_match[3].zfill(2)\n",
        "                    mois = date_match[4].zfill(2)\n",
        "                    annee = date_match[5]\n",
        "                    dates_pub.append(f\"{jour}/{mois}/{annee}\")\n",
        "\n",
        "    # Si plusieurs dates sont trouvées, on sélectionne la plus récente\n",
        "    if dates_pub:\n",
        "        # Convertir les dates en objets datetime\n",
        "        dates_pub_datetime = [datetime.strptime(date, \"%d/%m/%Y\") for date in dates_pub]\n",
        "        # Trouver la plus récente\n",
        "        latest_date = max(dates_pub_datetime)\n",
        "        return latest_date.strftime(\"%d/%m/%Y\")  # Retourner la date la plus récente sous forme de chaîne\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Appliquer la fonction à la colonne 'text version' du DataFrame df\n",
        "df['extracted_publication_date'] = df['text version'].apply(extract_publication_date)\n",
        "\n",
        "# Afficher les résultats\n",
        "print(df[['url', 'extracted_publication_date']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJoPHbA0KmZh",
        "outputId": "9cb3d616-493a-49f0-b27d-79ec36c1b0a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   url  \\\n",
            "0    http://www.ville-saint-ay.fr/userfile/fichier-...   \n",
            "1    https://www.gatine-racan.fr/wp-content/uploads...   \n",
            "2    https://www.ville-mazeres.fr/IMG/pdf/2023_1_1.pdf   \n",
            "3    https://www.fier-et-usses.com/cms_viewFile.php...   \n",
            "4    https://www.grandbourg.fr/cms_viewFile.php?idt...   \n",
            "..                                                 ...   \n",
            "495  https://plombieres-les-dijon.fr/wp-content/upl...   \n",
            "496  https://www.orne.gouv.fr/contenu/telechargemen...   \n",
            "497  https://www.vosges.gouv.fr/contenu/telechargem...   \n",
            "498  http://www.grandchambery.fr/fileadmin/mediathe...   \n",
            "499  http://www.hauts-de-seine.fr/fileadmin/user_up...   \n",
            "\n",
            "    extracted_publication_date  \n",
            "0                         None  \n",
            "1                         None  \n",
            "2                   02/02/2023  \n",
            "3                   26/01/2023  \n",
            "4                         None  \n",
            "..                         ...  \n",
            "495                       None  \n",
            "496                       None  \n",
            "497                       None  \n",
            "498                       None  \n",
            "499                       None  \n",
            "\n",
            "[500 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's display the rows where a publication date has actually been extracted:"
      ],
      "metadata": {
        "id": "1cECG-hYlJBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "valeurs_non_none = df.loc[df['extracted_publication_date'].notna(), ['extracted_publication_date', 'url']]\n",
        "valeurs_non_none"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Of1cF0YSYkGN",
        "outputId": "d1843c5a-3a3d-47ea-b356-b0620ebcb93c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    extracted_publication_date  \\\n",
              "2                   02/02/2023   \n",
              "3                   26/01/2023   \n",
              "6                   13/02/2023   \n",
              "8                   16/02/2023   \n",
              "9                   22/02/2023   \n",
              "..                         ...   \n",
              "487                 16/07/2020   \n",
              "488                 16/07/2020   \n",
              "489                 16/07/2020   \n",
              "491                 26/12/2023   \n",
              "493                 31/01/2024   \n",
              "\n",
              "                                                   url  \n",
              "2    https://www.ville-mazeres.fr/IMG/pdf/2023_1_1.pdf  \n",
              "3    https://www.fier-et-usses.com/cms_viewFile.php...  \n",
              "6    http://www.villeneuve-tolosane.fr/ad_attachmen...  \n",
              "8    https://www.guingamp-paimpol-agglo.bzh/wp-cont...  \n",
              "9    https://www.ales.fr/wp-content/uploads/2023/04...  \n",
              "..                                                 ...  \n",
              "487  https://www.cc-flandrelys.fr/images/2-VIVRE-ET...  \n",
              "488  https://www.cc-flandrelys.fr/images/2-VIVRE-ET...  \n",
              "489  https://www.cc-flandrelys.fr/images/2-VIVRE-ET...  \n",
              "491  https://www.gennesvaldeloire.fr/medias/2024/03...  \n",
              "493  https://www.saintcyr78.fr/wp-content/uploads/2...  \n",
              "\n",
              "[150 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-310c4041-71ea-4e7a-9261-cb4a9844f8f4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>extracted_publication_date</th>\n",
              "      <th>url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>02/02/2023</td>\n",
              "      <td>https://www.ville-mazeres.fr/IMG/pdf/2023_1_1.pdf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>26/01/2023</td>\n",
              "      <td>https://www.fier-et-usses.com/cms_viewFile.php...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>13/02/2023</td>\n",
              "      <td>http://www.villeneuve-tolosane.fr/ad_attachmen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>16/02/2023</td>\n",
              "      <td>https://www.guingamp-paimpol-agglo.bzh/wp-cont...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>22/02/2023</td>\n",
              "      <td>https://www.ales.fr/wp-content/uploads/2023/04...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>487</th>\n",
              "      <td>16/07/2020</td>\n",
              "      <td>https://www.cc-flandrelys.fr/images/2-VIVRE-ET...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>488</th>\n",
              "      <td>16/07/2020</td>\n",
              "      <td>https://www.cc-flandrelys.fr/images/2-VIVRE-ET...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489</th>\n",
              "      <td>16/07/2020</td>\n",
              "      <td>https://www.cc-flandrelys.fr/images/2-VIVRE-ET...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>491</th>\n",
              "      <td>26/12/2023</td>\n",
              "      <td>https://www.gennesvaldeloire.fr/medias/2024/03...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>493</th>\n",
              "      <td>31/01/2024</td>\n",
              "      <td>https://www.saintcyr78.fr/wp-content/uploads/2...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-310c4041-71ea-4e7a-9261-cb4a9844f8f4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-310c4041-71ea-4e7a-9261-cb4a9844f8f4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-310c4041-71ea-4e7a-9261-cb4a9844f8f4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-11584add-9edf-41d1-8320-4b452dd99fd1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-11584add-9edf-41d1-8320-4b452dd99fd1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-11584add-9edf-41d1-8320-4b452dd99fd1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_9c3b167e-fde4-432f-9b6c-87b999d17fb7\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('valeurs_non_none')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9c3b167e-fde4-432f-9b6c-87b999d17fb7 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('valeurs_non_none');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "valeurs_non_none",
              "summary": "{\n  \"name\": \"valeurs_non_none\",\n  \"rows\": 150,\n  \"fields\": [\n    {\n      \"column\": \"extracted_publication_date\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 116,\n        \"samples\": [\n          \"06/07/2020\",\n          \"22/02/2023\",\n          \"17/02/2020\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 150,\n        \"samples\": [\n          \"https://www.mairie-bailly.fr/wp-content/uploads/2024/03/Delib-2024-06-Delegation-de-competence-reseaux-de-chaleur-au-SEY.pdf\",\n          \"https://www.villeneuve-saint-georges.fr/images/agenda/13112017/pdf/ACTES/URBANISME/2023/MARS/PC-94078-2200041-1-MARS-2023.pdf\",\n          \"http://www.illkirch.eu/wp-content/uploads/conseil-municipal/CM_20200928/CM_20200928_point1c.pdf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that we obtain dates for 150 documents out of 500. We explain this number by the fact that there is no explicit terms about publication in every of the 500 documents. So this suggests that there are explicit terms about 'publication' in 150 documents.\n",
        "\n",
        "Let's analize this result by comparing it with our gold dates: for that we merge the two dataframes on the 'url' column:"
      ],
      "metadata": {
        "id": "GTVsj7eg0h5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fusionner les DataFrames df et df_gold sur la colonne 'url'\n",
        "df_merged = pd.merge(df.loc[df['extracted_publication_date'].notna(), ['url', 'extracted_publication_date']],\n",
        "                     df_gold[['url', 'Gold published date']],\n",
        "                     on='url',\n",
        "                     how='inner')\n",
        "\n",
        "# Comparer les dates\n",
        "df_merged['date_match'] = df_merged['extracted_publication_date'] == df_merged['Gold published date']\n",
        "\n",
        "# Afficher les résultats\n",
        "print(df_merged.head())\n",
        "\n",
        "# Calculer le pourcentage de 'True' dans la colonne 'date_match'\n",
        "percentage_true = df_merged['date_match'].mean() * 100\n",
        "percentage_true\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-X3JPZN0hnJ",
        "outputId": "e66f4a12-f381-42a9-d578-9c2a5092885e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 url  \\\n",
            "0  https://www.ville-mazeres.fr/IMG/pdf/2023_1_1.pdf   \n",
            "1  https://www.fier-et-usses.com/cms_viewFile.php...   \n",
            "2  http://www.villeneuve-tolosane.fr/ad_attachmen...   \n",
            "3  https://www.guingamp-paimpol-agglo.bzh/wp-cont...   \n",
            "4  https://www.ales.fr/wp-content/uploads/2023/04...   \n",
            "\n",
            "  extracted_publication_date Gold published date  date_match  \n",
            "0                 02/02/2023          02/02/2023        True  \n",
            "1                 26/01/2023          26/01/2023        True  \n",
            "2                 13/02/2023          13/02/2023        True  \n",
            "3                 16/02/2023          16/02/2023        True  \n",
            "4                 22/02/2023          22/02/2023        True  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62.66666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have an accuracy of 62.67 for the extracted_publication_date function."
      ],
      "metadata": {
        "id": "NDq4m9Sy7POo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_gold[df_gold['Gold published date'].isnull()] # 9 gold dates None"
      ],
      "metadata": {
        "id": "EJpuFBzGKruA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if we want to display the rows where the date_match is False:\n",
        "df_no_match = df_merged[df_merged['date_match'] == False]\n",
        "df_no_match\n",
        "# df_no_match.to_string()"
      ],
      "metadata": {
        "id": "YwBKxeOk9Onk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analysis of the result:**\n",
        "\n",
        "So we obtain 62.67 % of True matching between the gold dates and the dates extracted from this function.\\\n",
        "In any case, at the end we will check every extracted date that respects our criteria and we will choose the most recent.\n",
        "\n",
        "So we extracted dates only from 150 documents. To continue this process of extraction, we will now focus on the rest of the documents: we will use our second strategy which is to **extract all the dates** in the **beginning** of the document and at the **very end** of the document, and choose the latest, if there is no occurrence of words like \"annonce\" or \"à compter du\" or a future tense in the sentence. \\\n",
        "\n",
        "Finally, to avoid the None, we extract the FIRST date mentionned in the document if no dates are found according to our criteria. (And then again, at the end we will do a comparison of all the extracted dates to select the most recent one)"
      ],
      "metadata": {
        "id": "2JAmTTxPoVNL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Dates in the beginning/end of the document according to specific criteria"
      ],
      "metadata": {
        "id": "Vn-p3RwaoMZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function that extracts the most recent date (without mentioning future measures in the sentence) in the beginning/end\n",
        "# and the first date mentionned if None\n",
        "\n",
        "import requests\n",
        "import re\n",
        "from datetime import datetime\n",
        "\n",
        "def extract_most_recent_date(url):\n",
        "    # Télécharger le contenu du texte à partir de l'URL\n",
        "    response = requests.get(url)\n",
        "    if response.status_code != 200:  # Si le texte brut n'est pas disponible via l'URL\n",
        "        content = extract_text_from_pdf_url(df['url'])\n",
        "    else:  # Si le texte dans l'URL est disponible\n",
        "        content = response.text\n",
        "\n",
        "    content = content.lower()\n",
        "    mots = content.split()  # Séparer le contenu en mots\n",
        "\n",
        "    # Sélectionner les 300 premiers mots et les 100 derniers\n",
        "    extrait = mots[:300] + mots[-100:]\n",
        "    extrait_texte = \" \".join(extrait)\n",
        "\n",
        "    # Regex pour reconnaître les dates au format \"12 décembre 2023\" ou \"12/12/2023\"\n",
        "    pattern = r'(\\d{1,2})\\s*(janvier|février|mars|avril|mai|juin|juillet|août|septembre|octobre|novembre|décembre)\\s*(\\d{4})|(\\d{1,2})\\s*\\/\\s*(\\d{1,2})\\s*\\/\\s*(\\d{4})'\n",
        "\n",
        "    # Dictionnaire pour convertir les noms des mois en chiffres\n",
        "    mois_to_num = {\n",
        "        \"janvier\": \"01\", \"février\": \"02\", \"mars\": \"03\", \"avril\": \"04\", \"mai\": \"05\", \"juin\": \"06\",\n",
        "        \"juillet\": \"07\", \"août\": \"08\", \"septembre\": \"09\", \"octobre\": \"10\", \"novembre\": \"11\", \"décembre\": \"12\"\n",
        "    }\n",
        "\n",
        "    # Trouver toutes les dates dans l'extrait\n",
        "    matches = re.findall(pattern, extrait_texte)\n",
        "\n",
        "    # Transformer les dates en format standard et les filtrer selon les conditions\n",
        "    dates = []\n",
        "    premiere_date = None  # Stocker la première date rencontrée\n",
        "    for match in matches:\n",
        "        # Vérifier si la date est au format \"dd/mm/yyyy\"\n",
        "        if match[0] == '':  # Si match[0] est vide, c'est le format \"dd/mm/yyyy\"\n",
        "            jour = match[3].zfill(2)\n",
        "            mois = match[4].zfill(2)\n",
        "            annee = match[5]\n",
        "        else:  # Sinon, c'est le format \"dd mois yyyy\"\n",
        "            jour = match[0].zfill(2)\n",
        "            mois = mois_to_num[match[1].lower()]  # Convertir le mois en numéro\n",
        "            annee = match[2]\n",
        "\n",
        "        date_complete = f\"{jour}/{mois}/{annee}\"\n",
        "\n",
        "        # Stocker la première date rencontrée si aucune n'a été sauvegardée\n",
        "        if premiere_date is None:\n",
        "            premiere_date = date_complete\n",
        "\n",
        "        # Vérifier les conditions d'exclusion\n",
        "        phrase = re.search(rf'[^.]*{match[0]} {match[1]} {match[2]}[^.]*\\.', extrait_texte)\n",
        "        if phrase:\n",
        "            phrase = phrase.group(0)\n",
        "            if any(verbe in phrase for verbe in [\"annonce\", \"à compter d\"]) or re.search(r\"\\bfutur\\b\", phrase):\n",
        "                continue\n",
        "\n",
        "        # Ajouter la date si elle passe le filtre\n",
        "        dates.append(date_complete)\n",
        "\n",
        "    # Convertir les dates en objets datetime pour les trier\n",
        "    dates_obj = [datetime.strptime(date, \"%d/%m/%Y\") for date in dates]\n",
        "    if dates_obj:\n",
        "        # Retourner la date la plus récente si des dates valides ont été trouvées\n",
        "        date_plus_recente = max(dates_obj)\n",
        "        return date_plus_recente.strftime(\"%d/%m/%Y\")\n",
        "    else:\n",
        "        # Si aucune date valide n'a été trouvée, retourner la première date rencontrée\n",
        "        return premiere_date\n",
        "\n",
        "# Appliquer la fonction à la colonne 'text version' du DataFrame df\n",
        "df['extracted_most_recent_date'] = df['text version'].apply(extract_most_recent_date)\n",
        "\n",
        "# Afficher les résultats\n",
        "print(df[['url', 'extracted_most_recent_date']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMVMLyhMlwkf",
        "outputId": "d3e53339-daee-4c3e-c391-21410ca140ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   url  \\\n",
            "0    http://www.ville-saint-ay.fr/userfile/fichier-...   \n",
            "1    https://www.gatine-racan.fr/wp-content/uploads...   \n",
            "2    https://www.ville-mazeres.fr/IMG/pdf/2023_1_1.pdf   \n",
            "3    https://www.fier-et-usses.com/cms_viewFile.php...   \n",
            "4    https://www.grandbourg.fr/cms_viewFile.php?idt...   \n",
            "..                                                 ...   \n",
            "495  https://plombieres-les-dijon.fr/wp-content/upl...   \n",
            "496  https://www.orne.gouv.fr/contenu/telechargemen...   \n",
            "497  https://www.vosges.gouv.fr/contenu/telechargem...   \n",
            "498  http://www.grandchambery.fr/fileadmin/mediathe...   \n",
            "499  http://www.hauts-de-seine.fr/fileadmin/user_up...   \n",
            "\n",
            "    extracted_most_recent_date  \n",
            "0                   12/12/2023  \n",
            "1                   25/01/2023  \n",
            "2                   02/02/2023  \n",
            "3                   26/01/2023  \n",
            "4                   23/01/2023  \n",
            "..                         ...  \n",
            "495                 24/01/2024  \n",
            "496                 09/01/2024  \n",
            "497                 22/11/2022  \n",
            "498                 21/12/2023  \n",
            "499                 22/12/2023  \n",
            "\n",
            "[500 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking if we have \"None\" dates:\n",
        "df[df['extracted_most_recent_date'].isna()]"
      ],
      "metadata": {
        "id": "-T7xiGnkkSIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have 18 None dates. Indeed, even if we added a feature in our function to extract the **first** date mentionned in the document if no other is found, it can happen that \\\n",
        "1) the pdf is not readable (as said in the beginning)\\\n",
        "2) the text version url is damaged leading to missing caracters\\\n",
        "3) the text from the pdf url was not correctly read (through PyPDF2)."
      ],
      "metadata": {
        "id": "qRAfcBEgplMa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To complete this, because sometimes there is no publication date written in the document, we will finally **use the url**:\n",
        "\n",
        "- after extracting a date in the document, we will compare it to the one in the url and if the url date is later we take the url date, and if the url date is before, we keep the date extracted from the document.\n",
        "- if there is no publication date in the document, we compare the first date found in the document with the date in the url and we take the most recent one."
      ],
      "metadata": {
        "id": "trxqrCYBoKyu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Third step: we extract the dates from the url (if exists) in a third date column in the df ('extracted_url_date')."
      ],
      "metadata": {
        "id": "CFi4q1wNXEIr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Dates in the URLs"
      ],
      "metadata": {
        "id": "qAcggtwqJH__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unidecode"
      ],
      "metadata": {
        "collapsed": true,
        "id": "s2er27pnOv2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from unidecode import unidecode\n",
        "\n",
        "def extract_date_from_url(url):\n",
        "    # Mappage des mois (lettres vers chiffres)\n",
        "    month_map = {\n",
        "        \"janvier\": 1, \"jan\": 1, \"fevrier\": 2, \"fev\": 2,\n",
        "        \"mars\": 3, \"avril\": 4, \"avr\": 4, \"mai\": 5, \"juin\": 6, \"juillet\": 7,\n",
        "        \"août\": 8, \"aout\": 8, \"septembre\": 9, \"sept\": 9, \"octobre\": 10, \"oct\": 10,\n",
        "        \"novembre\": 11, \"nov\": 11, \"decembre\": 12, \"dec\": 12\n",
        "    }\n",
        "\n",
        "    # Listes d'expressions régulières pour capturer divers formats\n",
        "    patterns = [\n",
        "        # Format avec année en premier : 2023-01-16 ou 2023/01/16\n",
        "        r'(\\d{4})[-_/\\.](\\d{1,2})[-_/\\.](\\d{1,2})',\n",
        "        # Format classique : jour-mois-année (25-01-2023, 25.01.23)\n",
        "        r'(\\d{1,2})[-_/\\.](\\d{1,2})[-_/\\.](\\d{2,4})',\n",
        "        # Mois écrit en toutes lettres : jour mois année (21_decembre_2023, 16-fevrier-2023)\n",
        "        r'(\\d{1,2})[_-](janvier|fevrier|mars|avril|mai|juin|juillet|aout|septembre|octobre|novembre|decembre|jan|fev|mar|avr|mai|jun|jul|aou|sep|oct|nov|dec)[_-](\\d{2,4})',\n",
        "        # Cas spécifique : \"1er février 2023\"\n",
        "        r'(1er)[^\\w]*(janvier|fevrier|mars|avril|mai|juin|juillet|aout|septembre|octobre|novembre|decembre|jan|fev|mar|avr|mai|jun|jul|aou|sep|oct|nov|dec)[^\\w]*(\\d{2,4})',\n",
        "        # Format compact année-mois-jour : 20230126\n",
        "        r'(\\d{4})(\\d{2})(\\d{2})',\n",
        "        # Format compact jour-mois-année : 30012023 (doit être isolé)\n",
        "        r'\\b(\\d{2})(\\d{2})(\\d{4})\\b'\n",
        "    ]\n",
        "\n",
        "    url_normalized = unidecode(url)\n",
        "\n",
        "    # Premièrement, tenter de trouver une date dans les formats plus complexes\n",
        "    for pattern in patterns[:4]:\n",
        "        match = re.search(pattern, url_normalized, re.IGNORECASE)\n",
        "        if match:\n",
        "            groups = match.groups()\n",
        "            try:\n",
        "                if pattern == patterns[0]:  # Année-Mois-Jour (2023-01-16)\n",
        "                    year, month, day = map(int, groups)\n",
        "                elif pattern == patterns[1]:  # Jour-Mois-Année (25-01-2023)\n",
        "                    day, month, year = map(int, groups)\n",
        "                elif pattern == patterns[2]:  # Jour Mois en Lettres Année (21_decembre_2023)\n",
        "                    day, month_str, year = groups\n",
        "                    day = int(day)\n",
        "                    month = month_map[month_str.lower()]\n",
        "                    year = int(year)\n",
        "                elif pattern == patterns[3]:  # \"1er février 2023\"\n",
        "                    day = 1\n",
        "                    month = month_map[groups[1].lower()]\n",
        "                    year = int(groups[2])\n",
        "\n",
        "                # Vérifier la validité de la date\n",
        "                if 1 <= day <= 31 and 1 <= month <= 12:\n",
        "                    # Corrige l'année si elle est sur 2 chiffres\n",
        "                    if year < 100:\n",
        "                        year += 2000\n",
        "                    return day, month, year\n",
        "            except (ValueError, KeyError):\n",
        "                continue\n",
        "\n",
        "    # Ensuite, traiter les dates au format compact, mais seulement si elles sont isolées (ex : 30012023)\n",
        "    match = re.search(patterns[4], url_normalized)\n",
        "    if match:\n",
        "        groups = match.groups()\n",
        "        try:\n",
        "            year, month, day = map(int, groups)\n",
        "\n",
        "            # Vérifier la validité de la date\n",
        "            if 1 <= day <= 31 and 1 <= month <= 12:\n",
        "                # Corrige l'année si elle est sur 2 chiffres\n",
        "                if year < 100:\n",
        "                    year += 2000\n",
        "                return day, month, year\n",
        "        except (ValueError, KeyError):\n",
        "            pass\n",
        "\n",
        "    # Enfin, gérer le format de date sous la forme ddmmyyyy (ex : 30012023) isolé dans l'URL\n",
        "    match = re.search(patterns[5], url_normalized)\n",
        "    if match:\n",
        "        groups = match.groups()\n",
        "        try:\n",
        "            day, month, year = map(int, groups)\n",
        "\n",
        "            # Vérifier la validité de la date\n",
        "            if 1 <= day <= 31 and 1 <= month <= 12:\n",
        "                # Corrige l'année si elle est sur 2 chiffres\n",
        "                if year < 100:\n",
        "                    year += 2000\n",
        "                return day, month, year\n",
        "        except (ValueError, KeyError):\n",
        "            pass\n",
        "\n",
        "    return None, None, None  # Si aucune date n'est trouvée\n",
        "\n",
        "\n",
        "# Appliquer la fonction pour extraire la date\n",
        "df['extracted_url_date'] = df['url'].apply(\n",
        "    lambda url: \"{:02d}/{:02d}/{:04d}\".format(*extract_date_from_url(url)) if all(extract_date_from_url(url)) else None\n",
        ")\n",
        "\n",
        "# Afficher le DataFrame avec les dates extraites\n",
        "df[['url', 'extracted_url_date']]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "nR46-w3pUOqp",
        "outputId": "1a4db24e-7ed3-4756-dc3f-0d4c72429609"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   url extracted_url_date\n",
              "0    http://www.ville-saint-ay.fr/userfile/fichier-...         16/01/2023\n",
              "1    https://www.gatine-racan.fr/wp-content/uploads...         25/01/2023\n",
              "2    https://www.ville-mazeres.fr/IMG/pdf/2023_1_1.pdf         01/01/2023\n",
              "3    https://www.fier-et-usses.com/cms_viewFile.php...               None\n",
              "4    https://www.grandbourg.fr/cms_viewFile.php?idt...         16/01/2023\n",
              "..                                                 ...                ...\n",
              "495  https://plombieres-les-dijon.fr/wp-content/upl...         24/01/2024\n",
              "496  https://www.orne.gouv.fr/contenu/telechargemen...               None\n",
              "497  https://www.vosges.gouv.fr/contenu/telechargem...               None\n",
              "498  http://www.grandchambery.fr/fileadmin/mediathe...         21/12/2023\n",
              "499  http://www.hauts-de-seine.fr/fileadmin/user_up...         22/12/2023\n",
              "\n",
              "[500 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-526706b7-50e6-4280-8b63-f177b8bdc9e3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>extracted_url_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>http://www.ville-saint-ay.fr/userfile/fichier-...</td>\n",
              "      <td>16/01/2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.gatine-racan.fr/wp-content/uploads...</td>\n",
              "      <td>25/01/2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://www.ville-mazeres.fr/IMG/pdf/2023_1_1.pdf</td>\n",
              "      <td>01/01/2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://www.fier-et-usses.com/cms_viewFile.php...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.grandbourg.fr/cms_viewFile.php?idt...</td>\n",
              "      <td>16/01/2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>https://plombieres-les-dijon.fr/wp-content/upl...</td>\n",
              "      <td>24/01/2024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>https://www.orne.gouv.fr/contenu/telechargemen...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>https://www.vosges.gouv.fr/contenu/telechargem...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>http://www.grandchambery.fr/fileadmin/mediathe...</td>\n",
              "      <td>21/12/2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>http://www.hauts-de-seine.fr/fileadmin/user_up...</td>\n",
              "      <td>22/12/2023</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-526706b7-50e6-4280-8b63-f177b8bdc9e3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-526706b7-50e6-4280-8b63-f177b8bdc9e3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-526706b7-50e6-4280-8b63-f177b8bdc9e3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e4a04863-63c7-4f35-bc17-33d7acde528f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e4a04863-63c7-4f35-bc17-33d7acde528f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e4a04863-63c7-4f35-bc17-33d7acde528f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df[['url', 'extracted_url_date']]\",\n  \"rows\": 500,\n  \"fields\": [\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"https://www.ville-cachan.fr/images/CR_CM_19_11_20.pdf\",\n          \"https://www.villeneuve-saint-georges.fr/images/agenda/13112017/pdf/ACTES/URBANISME/2023/MARS/PC-94078-2200041-1-MARS-2023.pdf\",\n          \"https://www.gennesvaldeloire.fr/medias/2021/02/Compte-rendu-sommaire-du-08.02.2021.pdf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"extracted_url_date\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 209,\n        \"samples\": [\n          \"09/02/2023\",\n          \"31/08/2020\",\n          \"03/01/2020\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Final extraction"
      ],
      "metadata": {
        "id": "pwOB1G3qreEc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we will get the most recent date from all of the 3 columns of extracted dates, according to the 3 functions we executed:\n",
        "\n",
        "1. Extracted publication date (along specific terms in the text)\n",
        "2. Extracted most recent date (in the whole text, along specific criteria)\n",
        "3. Extracted url date\n"
      ],
      "metadata": {
        "id": "QuPfCswqi6YR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to datetime, handling errors\n",
        "for col in ['extracted_publication_date', 'extracted_most_recent_date', 'extracted_url_date']:\n",
        "    df[col] = pd.to_datetime(df[col], format='%d/%m/%Y', errors='coerce')\n",
        "    # errors='coerce' will set invalid dates to NaT (Not a Time)\n",
        "\n",
        "# We take the most recent date from the 3 columns\n",
        "df['real_publication_date'] = df[['extracted_publication_date', 'extracted_most_recent_date', 'extracted_url_date']].max(axis=1)\n",
        "\n",
        "# Convertir la colonne 'publication' en format datetime (YYYY-MM-DD)\n",
        "df['publication'] = pd.to_datetime(df['published'], errors='coerce')\n",
        "# Compléter real_publication_date avec les dates de 'publication' là où il y a NaT\n",
        "df['real_publication_date'] = df['real_publication_date'].fillna(df['published'])\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "Yb3Mn2YqXPKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[['url','extracted_publication_date', 'extracted_most_recent_date', 'extracted_url_date','real_publication_date']].to_string())"
      ],
      "metadata": {
        "id": "vYGbXgFpqSEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Evaluation\n",
        "\n",
        "Comparison to the gold dates"
      ],
      "metadata": {
        "id": "LjNZkXvVjZIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged_f = df.merge(df_gold, on=\"url\", how=\"inner\")\n",
        "\n",
        "# conversion de la colonne \"Gold published date\" en format datetime pour matcher le format de toutes les autres dates\n",
        "df_merged_f['Gold published date_format'] = pd.to_datetime(df_merged_f['Gold published date'], errors='coerce')\n",
        "\n",
        "# Comparer les dates\n",
        "df_merged_f['date_match'] = df_merged_f['real_publication_date'] == df_merged_f['Gold published date_format']\n",
        "\n",
        "# Afficher les résultats\n",
        "print(df_merged_f.head())\n",
        "\n",
        "# Calculer le pourcentage de 'True' dans la colonne 'date_match'\n",
        "percentage_true_f = df_merged_f['date_match'].mean() * 100\n",
        "\n",
        "# Afficher le pourcentage\n",
        "percentage_true_f"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_ooU8eejbvg",
        "outputId": "db1203e3-180e-4fa7-ee72-c397126f3f71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              doc_id  \\\n",
            "0  6357/71845_1698228833-PV---Conseil-Municipal-1...   \n",
            "1            2515/213c7_proces-verbal-25-01-2023.pdf   \n",
            "2                            1086/ee2ec_2023_1_1.pdf   \n",
            "3                        3020/68132_cms_viewFile.php   \n",
            "4                        3132/6df22_cms_viewFile.php   \n",
            "\n",
            "                                                 url  \\\n",
            "0  http://www.ville-saint-ay.fr/userfile/fichier-...   \n",
            "1  https://www.gatine-racan.fr/wp-content/uploads...   \n",
            "2  https://www.ville-mazeres.fr/IMG/pdf/2023_1_1.pdf   \n",
            "3  https://www.fier-et-usses.com/cms_viewFile.php...   \n",
            "4  https://www.grandbourg.fr/cms_viewFile.php?idt...   \n",
            "\n",
            "                                               cache  \\\n",
            "0  https://datapolitics-public.s3.gra.io.cloud.ov...   \n",
            "1  https://datapolitics-public.s3.gra.io.cloud.ov...   \n",
            "2  https://datapolitics-public.s3.gra.io.cloud.ov...   \n",
            "3  https://datapolitics-public.s3.gra.io.cloud.ov...   \n",
            "4  https://datapolitics-public.s3.gra.io.cloud.ov...   \n",
            "\n",
            "                                        text version      nature   published  \\\n",
            "0  https://datapolitics-public.s3.gra.io.cloud.ov...       pv.cr  16/01/2023   \n",
            "1  https://datapolitics-public.s3.gra.io.cloud.ov...       pv.cr  25/01/2023   \n",
            "2  https://datapolitics-public.s3.gra.io.cloud.ov...       pv.cr  31/01/2023   \n",
            "3  https://datapolitics-public.s3.gra.io.cloud.ov...  acte.delib  26/01/2023   \n",
            "4  https://datapolitics-public.s3.gra.io.cloud.ov...       pv.cr  16/01/2023   \n",
            "\n",
            "                            entity       entity_type  \\\n",
            "0                         Saint-Ay           Commune   \n",
            "1               CC de Gâtine-Racan  Intercommunalité   \n",
            "2                          Mazères           Commune   \n",
            "3                 CC Fier et Usses  Intercommunalité   \n",
            "4  CA du Bassin de Bourg-en-Bresse  Intercommunalité   \n",
            "\n",
            "  extracted_publication_date extracted_most_recent_date extracted_url_date  \\\n",
            "0                        NaT                 2023-12-12         2023-01-16   \n",
            "1                        NaT                 2023-01-25         2023-01-25   \n",
            "2                 2023-02-02                 2023-02-02         2023-01-01   \n",
            "3                 2023-01-26                 2023-01-26                NaT   \n",
            "4                        NaT                 2023-01-23         2023-01-16   \n",
            "\n",
            "  real_publication_date publication  \\\n",
            "0            2023-12-12  2023-01-16   \n",
            "1            2023-01-25  2023-01-25   \n",
            "2            2023-02-02  2023-01-31   \n",
            "3            2023-01-26  2023-01-26   \n",
            "4            2023-01-23  2023-01-16   \n",
            "\n",
            "                                                Text Gold published date  \\\n",
            "0  PROCES-VERBAL DE LA REUNION PUBLIQUE\\nDU CONSE...          16/01/2023   \n",
            "1  CONSEIL COMMUNAUTAIRE DU\\n25 JANVIER 2023\\nPRO...          25/01/2023   \n",
            "2  Date de mise en ligne de\\nl’acte : 02/ 02/2023...          02/02/2023   \n",
            "3  Envoyé en préfecture le 26/01/2023\\nReçu en pr...          26/01/2023   \n",
            "4       \\nFait à Bourg-en-Bresse, le 23 janvier 2023          23/01/2023   \n",
            "\n",
            "  Gold published date_format  date_match  \n",
            "0                 2023-01-16       False  \n",
            "1                 2023-01-25        True  \n",
            "2                 2023-02-02        True  \n",
            "3                 2023-01-26        True  \n",
            "4                 2023-01-23        True  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-58-45789c8e2c7a>:4: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
            "  df_merged_f['Gold published date_format'] = pd.to_datetime(df_merged_f['Gold published date'], errors='coerce')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60.199999999999996"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We obtain an accuracy of 60.2"
      ],
      "metadata": {
        "id": "ZKHtV6DUaPbr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretation**:\n",
        "\n",
        "The functions that we made encompassed a lot of the different cases in the documents, but not all, hence our accuracy.\n",
        "\n",
        "**Here are a few points to explain this score (while having expected a higher score due to the well designed functions we thoughfully made):**\n",
        "\n",
        "- it is very possible (not to say certain) that the dates extracted from our functions are the correct ones compared to the \"gold dates\". Indeed, sometimes the computer functions are better than humans and in our case here, there are times where our annotators (students in the class) didn't notice the publication date, and sometimes it's even very difficult to deduce when a document was published when it is not said explicitely at all.\n",
        "- as mentionned before, there are pdf that were not readable\n",
        "- there were publication dates manually written on the documents (so, obviously not detectable here). An immprovement could be to use OCR.\n",
        "\n",
        "Now let's see another implementation method involving a fine-tuned model."
      ],
      "metadata": {
        "id": "vPY9o2atjV_o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Using a fine-tuned model"
      ],
      "metadata": {
        "id": "d6q7L90patWl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Goal: To extract the publication date of official documents accurately, using a combination of text analysis and URL-based fallback mechanisms.\n",
        "\n",
        "1. Data Preparation: The dataset contains official documents with their text, gold-standard publication dates (for evaluation), and URLs. The publication date may be explicitly mentioned in the text or inferred from patterns in the URL.\n",
        "\n",
        "2. Training and Prediction: A language model is fine-tuned (or prompted) to predict publication dates from the document's text. If the model cannot find a date in the text, a fallback mechanism extracts potential date information from the document's URL using regex.\n",
        "\n",
        "3. Fallback Logic:\n",
        "\n",
        "  - Primary Source: The model is prompted to extract the date from the document text, focusing on phrases indicating publication dates.\n",
        "  - Fallback Source: If the model fails or is uncertain, regex patterns scan the URL to identify date-like patterns.\n",
        "\n",
        "4. Evaluation: The predicted dates from the text and URLs are compared against the gold-standard publication dates. Rows where neither the model nor the URL extraction returns a valid date are excluded from accuracy calculations to avoid skewing results. Accuracy is defined as the proportion of cases where either the text-based or URL-based prediction matches the gold-standard date."
      ],
      "metadata": {
        "id": "zmW0JvMQm387"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets"
      ],
      "metadata": {
        "collapsed": true,
        "id": "uhbt6jD0cXnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import re\n",
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "# Disable Weights & Biases logging\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# 1. Load dataset\n",
        "gold_dataset = load_dataset(\"maribr/publication_dates_fr\")\n",
        "\n",
        "print(gold_dataset)\n",
        "\n",
        "# Convert dataset to pandas for easier processing\n",
        "df = pd.DataFrame(gold_dataset['train'])  # Use the train split for now\n",
        "print(f\"Loaded dataset with {len(df)} entries\")"
      ],
      "metadata": {
        "id": "2liZ3Miry1dJ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through all URLs in the DataFrame and print them\n",
        "for index, url in enumerate(df['url']):\n",
        "    print(url)"
      ],
      "metadata": {
        "id": "PUkeJTr0TcMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Data Cleaning: Remove invalid rows\n",
        "df = df[df['Text'].notna() & df['Gold published date'].notna() & df['url'].notna()]  # Ensure 'url' is not None\n",
        "df = df[(df['Text'].str.strip() != \"\") & (df['Gold published date'].str.strip() != \"\") & (df['url'].str.strip() != \"\")]  # Ensure 'url' is not empty\n",
        "\n",
        "print(f\"Filtered dataset: {len(df)} entries remain after cleaning.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCbwn6n7y-FF",
        "outputId": "9ccf3f82-0b54-4c1c-f7d9-de858329a72d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered dataset: 411 entries remain after cleaning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Split into training and testing sets\n",
        "train_test_split = df.sample(frac=0.8, random_state=42)  # 80% for training\n",
        "test_split = df.drop(train_test_split.index)  # 20% for testing\n",
        "\n",
        "# Convert splits to Hugging Face Dataset format\n",
        "train_dataset = Dataset.from_pandas(train_test_split)\n",
        "test_dataset = Dataset.from_pandas(test_split)\n",
        "\n",
        "print(f\"Training dataset: {len(train_dataset)} entries\")\n",
        "print(f\"Testing dataset: {len(test_dataset)} entries\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PN4dRjqzKWB",
        "outputId": "5083150e-91c8-4f63-8133-3126926aca98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset: 329 entries\n",
            "Testing dataset: 82 entries\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Prepare dataset for fine-tuning\n",
        "def prepare_data(row):\n",
        "    input_text = f\"\"\"\n",
        "    The following is an official document. Extract and return the publication date of this document.\n",
        "\n",
        "    - Focus on identifying the publication date as mentioned in the text of the document.\n",
        "    - If the publication date cannot be found in the text, you can check the following URL for potential date information: {row['url']}.\n",
        "    - Return the publication date as it appears in the text or URL.\n",
        "\n",
        "    Document:\n",
        "    {row['Text'][:2000]}\n",
        "\n",
        "    URL:\n",
        "    {row['url']}\n",
        "    \"\"\"\n",
        "    target_text = row['Gold published date']\n",
        "    return {\"input_text\": input_text, \"target_text\": target_text}\n",
        "\n",
        "train_dataset = train_dataset.map(lambda x: prepare_data(x), remove_columns=train_dataset.column_names)\n",
        "test_dataset = test_dataset.map(lambda x: prepare_data(x), remove_columns=test_dataset.column_names)\n",
        "\n",
        "print(\"Dataset preparation complete.\")"
      ],
      "metadata": {
        "id": "2B5ieA6O2JEm",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# 5. Load pre-trained model and tokenizer\n",
        "model_name = \"google/flan-t5-small\"  # Use larger models like flan-t5-base if needed\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "W1NNVfVd2XTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Preprocess data\n",
        "def preprocess_function(examples):\n",
        "    inputs = tokenizer(examples['input_text'], truncation=True, max_length=512, padding=\"max_length\")\n",
        "    labels = tokenizer(examples['target_text'], truncation=True, max_length=10, padding=\"max_length\").input_ids\n",
        "    inputs[\"labels\"] = labels\n",
        "    return inputs\n",
        "\n",
        "tokenized_train = train_dataset.map(preprocess_function, batched=True)\n",
        "tokenized_test = test_dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "print(\"Dataset preprocessing complete.\")"
      ],
      "metadata": {
        "id": "7HN1UrVM2hw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "# 7. Training configuration\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    logging_steps=5,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=5,\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "# 8. Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_test,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "# 9. Train the model\n",
        "print(\"Fine-tuning the model...\")\n",
        "trainer.train()\n",
        "\n",
        "# Save the fine-tuned model\n",
        "model.save_pretrained(\"./fine_tuned_model\")\n",
        "tokenizer.save_pretrained(\"./fine_tuned_model\")\n",
        "print(\"Model fine-tuned and saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "jqZRXgwP22Tt",
        "outputId": "8952b704-128e-426a-b2a5-d42ea32c1118"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-df40f613f4b2>:19: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuning the model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [105/105 1:10:40, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>17.406800</td>\n",
              "      <td>16.035885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>15.245300</td>\n",
              "      <td>13.530875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>13.885000</td>\n",
              "      <td>11.890170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>12.530300</td>\n",
              "      <td>10.955270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>12.070400</td>\n",
              "      <td>10.642661</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model fine-tuned and saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from datetime import datetime\n",
        "\n",
        "# 10. Normalize Dates\n",
        "def normalize_date(date_str):\n",
        "    try:\n",
        "        # Match standard format (DD/MM/YYYY)\n",
        "        if re.match(r\"\\b\\d{2}/\\d{2}/\\d{4}\\b\", date_str):\n",
        "            return date_str\n",
        "\n",
        "        # Match ISO format (YYYY-MM-DD)\n",
        "        iso_match = re.match(r\"\\b(\\d{4})-(\\d{2})-(\\d{2})\\b\", date_str)\n",
        "        if iso_match:\n",
        "            year, month, day = iso_match.groups()\n",
        "            return f\"{day}/{month}/{year}\"\n",
        "\n",
        "        # Define a comprehensive months mapping\n",
        "        months_map = {\n",
        "            **{\n",
        "                \"JANVIER\": \"01\", \"FEVRIER\": \"02\", \"MARS\": \"03\", \"AVRIL\": \"04\",\n",
        "                \"MAI\": \"05\", \"JUIN\": \"06\", \"JUILLET\": \"07\", \"AOUT\": \"08\",\n",
        "                \"SEPTEMBRE\": \"09\", \"OCTOBRE\": \"10\", \"NOVEMBRE\": \"11\", \"DECEMBRE\": \"12\"\n",
        "            },\n",
        "            **{\n",
        "                \"JANUARY\": \"01\", \"FEBRUARY\": \"02\", \"MARCH\": \"03\", \"APRIL\": \"04\",\n",
        "                \"MAY\": \"05\", \"JUNE\": \"06\", \"JULY\": \"07\", \"AUGUST\": \"08\",\n",
        "                \"SEPTEMBER\": \"09\", \"OCTOBER\": \"10\", \"NOVEMBER\": \"11\", \"DECEMBER\": \"12\"\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Match textual format (e.g., \"25 JANVIER 2023\" or \"25 October 2023\")\n",
        "        text_match = re.search(r\"(\\d{1,2})\\s([A-ZÉ]+)\\s(\\d{4})\", date_str.upper())\n",
        "        if text_match:\n",
        "            day, month, year = text_match.groups()\n",
        "            month = months_map.get(month)\n",
        "            if not month:\n",
        "                raise ValueError(f\"Unknown month: {month}\")\n",
        "            return f\"{int(day):02d}/{month}/{year}\"\n",
        "\n",
        "        # Match flexible formats like \"1/2/23\"\n",
        "        flexible_match = re.match(r\"(\\d{1,2})/(\\d{1,2})/(\\d{2,4})\", date_str)\n",
        "        if flexible_match:\n",
        "            day, month, year = flexible_match.groups()\n",
        "            if len(year) == 2:  # Expand two-digit year\n",
        "                year = f\"20{year}\"\n",
        "            return f\"{int(day):02d}/{int(month):02d}/{year}\"\n",
        "\n",
        "        return None  # Return None if no valid format\n",
        "    except Exception as e:\n",
        "        print(f\"Error normalizing date: {e}\")\n",
        "        return None\n",
        "\n",
        "def extract_date_from_url(url):\n",
        "    \"\"\"\n",
        "    Extract a potential date from the URL using regex patterns for common date formats.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Define regex patterns for different date formats\n",
        "        date_patterns = [\n",
        "            r\"(\\d{4})[/-](\\d{2})[/-](\\d{2})\",  # YYYY-MM-DD or YYYY/MM/DD\n",
        "            r\"(\\d{2})[/-](\\d{2})[/-](\\d{4})\",  # DD-MM-YYYY or DD/MM/YYYY\n",
        "            r\"(\\d{4})[/-](\\d{1,2})[/-](\\d{1,2})\",  # YYYY/M/D or YYYY-M-D\n",
        "            r\"(\\d{2})-(\\d{2})-(\\d{4})\",  # DD-MM-YYYY in filenames\n",
        "            r\"path=(\\d{4})-(\\d{2})-(\\d{2})\"  # YYYY-MM-DD in URL parameters\n",
        "        ]\n",
        "\n",
        "        # Iterate through patterns to find a match\n",
        "        for pattern in date_patterns:\n",
        "            match = re.search(pattern, url)\n",
        "            if match:\n",
        "                groups = list(map(int, match.groups()))  # Convert to integers for flexibility\n",
        "                if len(groups) == 3:\n",
        "                    day, month, year = None, None, None\n",
        "                    if groups[0] > 31:  # Assume YYYY-MM-DD\n",
        "                        year, month, day = groups\n",
        "                    elif groups[2] > 31:  # Assume DD-MM-YYYY\n",
        "                        day, month, year = groups\n",
        "                    else:  # Handle partial or flexible formats\n",
        "                        year, month, day = groups\n",
        "                    return f\"{day:02d}/{month:02d}/{year}\"\n",
        "\n",
        "        return None  # No match found\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting date from URL: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "HorIrJx73EOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Predict and normalize dates\n",
        "def predict_and_normalize_date(row):\n",
        "    prompt = f\"\"\"\n",
        "    The following is an official document. Extract and return the publication date of this document.\n",
        "\n",
        "    - Focus on identifying the publication date as mentioned in the text of the document.\n",
        "    - If the publication date cannot be found in the text, you can check the following URL for potential date information: {row['url']}.\n",
        "    - Return the publication date as it appears in the text or URL.\n",
        "\n",
        "    Document:\n",
        "    {row['Text'][:2000]}\n",
        "\n",
        "    URL:\n",
        "    {row['url']}\n",
        "    \"\"\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "    outputs = model.generate(**inputs, max_length=20)\n",
        "    raw_output = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
        "    print(f\"Raw Output: {raw_output}\")\n",
        "\n",
        "    normalized_date = normalize_date(raw_output)\n",
        "    if normalized_date:\n",
        "        print(f\"Normalized Date (from model): {normalized_date}\")\n",
        "    else:\n",
        "        print(\"Model failed to predict a valid date.\")\n",
        "\n",
        "    extracted_date = extract_date_from_url(row['url'])\n",
        "    if extracted_date:\n",
        "        print(f\"Date extracted from URL: {extracted_date}\")\n",
        "\n",
        "    return normalized_date, extracted_date\n",
        "\n",
        "# Apply prediction and normalization to the test set\n",
        "print(\"Predicting and normalizing dates...\")\n",
        "test_split[['predicted_date', 'url_date']] = test_split.apply(\n",
        "    lambda row: pd.Series(predict_and_normalize_date(row)), axis=1\n",
        ")"
      ],
      "metadata": {
        "id": "9gIVbftFGE4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. Evaluate predictions\n",
        "test_split['gold_date'] = pd.to_datetime(test_split['Gold published date'], format='%d/%m/%Y', errors='coerce')\n",
        "test_split['predicted_date'] = pd.to_datetime(test_split['predicted_date'], format='%d/%m/%Y', errors='coerce')\n",
        "test_split['url_date'] = pd.to_datetime(test_split['url_date'], format='%d/%m/%Y', errors='coerce')\n",
        "\n",
        "# Exclude rows where both predicted_date and url_date are None\n",
        "valid_rows = ~(\n",
        "    test_split['predicted_date'].isna() &\n",
        "    test_split['url_date'].isna()\n",
        ")\n",
        "\n",
        "# Calculate accuracy only for valid rows\n",
        "valid_test_split = test_split[valid_rows]\n",
        "valid_test_split['is_correct'] = (\n",
        "    (valid_test_split['predicted_date'] == valid_test_split['gold_date']) |\n",
        "    (valid_test_split['url_date'] == valid_test_split['gold_date'])\n",
        ")\n",
        "\n",
        "accuracy = valid_test_split['is_correct'].mean()\n",
        "print(f\"Accuracy (excluding rows with both dates missing): {accuracy:.2%}\")\n",
        "\n",
        "# Display mismatches for valid rows\n",
        "print(\"\\nExamples of mismatches:\")\n",
        "mismatches = valid_test_split[~valid_test_split['is_correct']]\n",
        "print(mismatches[['Gold published date', 'predicted_date', 'url_date']].head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frsxtxByIMB7",
        "outputId": "e18a265a-0081-4a27-c08b-dfe9e90b9da4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (excluding rows with both dates missing): 66.67%\n",
            "\n",
            "Examples of mismatches:\n",
            "    Gold published date predicted_date   url_date\n",
            "21           10/02/2023            NaT 2018-08-01\n",
            "167          13/12/2022            NaT 2023-02-04\n",
            "171          13/12/2022            NaT 2023-02-04\n",
            "186          12/02/2020            NaT 2020-03-20\n",
            "252          28/02/2924            NaT 2028-02-20\n",
            "334          29/02/2016            NaT 2022-03-06\n",
            "490          05/12/2023            NaT 2005-12-23\n",
            "493          31/01/2024            NaT 2024-02-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-45c9729d5789>:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  valid_test_split['is_correct'] = (\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy: 66.67%\n",
        "\n",
        "Potential Issues and Areas for Improvement\n",
        "1. Model Performance on Text\n",
        "\n",
        "  The model might not handle nuanced or varied date formats in the text well. Dates hidden in footnotes, metadata, or inconsistent phrasing could confuse the model. We need to check the proportion of correct predictions made by the model alone. If it contributes less to accuracy than URL parsing, it suggests the model requires further fine-tuning or prompt adjustments.\n",
        "\n",
        "2. URL Parsing Limitations\n",
        "\n",
        "  Regex patterns may miss unconventional or less-structured date formats in URLs. For example, URLs with encoded characters or non-standard date positions might bypass extraction rules. Maybe need to evaluate how many cases were resolved by URL extraction alone. If the performance is suboptimal, refine regex patterns or add more rules for edge cases.\n",
        "\n",
        "3. Gold Standard vs. Extracted Dates\n",
        "\n",
        "  Differences in date format or granularity (e.g., publication date vs. approval date) could cause false mismatches, reducing accuracy unfairly.\n",
        "  Further investigate mismatched cases to see if the extracted dates were semantically valid but differed from the gold standard."
      ],
      "metadata": {
        "id": "T0OkOjwZJ_a8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To conclude on our two approaches, the fine-tuned model resulted in a better accuracy (66.67%), compared to the brute force way with regex (60.2%). This demonstrates that leveraging machine learning techniques, such as fine-tuning, can outperform rule-based methods in handling complex tasks.\n",
        "\n",
        "But these two scores still show that this task of publication-date-extraction is difficult and results could have been better if we had only cleaned and readable documents, a perfectly reliable gold dates set, and other points described previously."
      ],
      "metadata": {
        "id": "r7yirXHnyh3A"
      }
    }
  ]
}